{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T03:20:24.185397Z",
     "start_time": "2025-02-18T03:20:24.182235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import json\n",
    "import math"
   ],
   "id": "5bf7201c9cf93635",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T03:22:21.726163Z",
     "start_time": "2025-02-18T03:22:21.225680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"raw_data/yellow_tripdata_2022-01.parquet\"\n",
    "trips = pq.read_table(file_path)\n",
    "trips = trips.to_pandas()\n",
    "# Drop datetime columns as per request\n",
    "trips = trips.drop(columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'VendorID'])\n",
    "\n",
    "# Group by PULocationID and DOLocationID, and summarize numeric columns\n",
    "summary_df = trips.groupby(['PULocationID', 'DOLocationID']).agg({\n",
    "    'passenger_count': ['sum', 'mean'],\n",
    "    'trip_distance': 'mean',\n",
    "    'RatecodeID': 'mean',\n",
    "    'fare_amount':'mean',\n",
    "    'extra': 'mean',\n",
    "    'mta_tax': 'mean',\n",
    "    'tip_amount': 'mean',\n",
    "    'tolls_amount': 'mean',\n",
    "    'improvement_surcharge': 'mean',\n",
    "    'total_amount': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "summary_df.columns = ['PULocationID', 'DOLocationID',\n",
    "                        'passenger_count_sum', 'passenger_count_mean',\n",
    "                        'trip_distance', 'RatecodeID', 'fare_amount',\n",
    "                        'extra', 'mta_tax', 'tip_amount',\n",
    "                        'tolls_amount', 'improvement_surcharge',\n",
    "                        'total_amount']\n",
    "\n",
    "summary_df = summary_df.fillna(0)\n",
    "# drop rows with passenger_count = 0\n",
    "summary_df = summary_df[summary_df['passenger_count'] != 0]\n",
    "summary_df = summary_df[summary_df['PULocationID'] < 263]\n",
    "summary_df = summary_df[summary_df['DOLocationID'] < 263]\n",
    "data_year_month = file_path.split('_')\n",
    "print(data_year_month)\n",
    "data_year_month = data_year_month[3].split('.')[0]\n",
    "print(data_year_month)\n",
    "\n",
    "lookup_df = pd.read_csv(\"taxi_zones_centroids.csv\")\n",
    "\n",
    "# Merge with lookup table to get coordinates for PULocationID (Pickup)\n",
    "summary_df = summary_df.merge(\n",
    "    lookup_df, how=\"left\", left_on=\"PULocationID\", right_on=\"LocationID\"\n",
    ").rename(columns={\"Longitude\": \"X_Longitude\", \"Latitude\": \"X_Latitude\"}).drop(columns=[\"LocationID\"])\n",
    "\n",
    "# Merge with lookup table to get coordinates for DOLocationID (Dropoff)\n",
    "summary_df = summary_df.merge(\n",
    "    lookup_df, how=\"left\", left_on=\"DOLocationID\", right_on=\"LocationID\"\n",
    ").rename(columns={\"Longitude\": \"Y_Longitude\", \"Latitude\": \"Y_Latitude\"}).drop(columns=[\"LocationID\"])\n",
    "\n",
    "\n",
    "# get the log of it\n",
    "summary_df[\"width\"] = summary_df['passenger_count'].apply(lambda x: math.log10(x))\n",
    "\n",
    "# Print the rows where there are NaN values in any of the longitude or latitude columns\n",
    "nan_rows = summary_df[summary_df[['X_Longitude', 'X_Latitude', 'Y_Longitude', 'Y_Latitude']].isna().any(axis=1)]\n",
    "\n",
    "# Display the rows with NaN values\n",
    "print(nan_rows)\n",
    "\n",
    "\n",
    "\n",
    "features = []\n",
    "for _, row in summary_df.iterrows():\n",
    "    feature = {\n",
    "        'type': 'Feature',\n",
    "        'properties': {\n",
    "            'color': '#000000',  # Use black for all lines\n",
    "            'lineThickness': row['width'],  # Use 'width' for line thickness\n",
    "            'PULocationID': row['PULocationID'],\n",
    "            'DOLocationID': row['DOLocationID'],\n",
    "            'passenger_count_sum': row['passenger_count_sum'],\n",
    "            'passenger_count_mean': row['passenger_count_mean'],\n",
    "            'trip_distance': row['trip_distance'],\n",
    "            'RatecodeID': row['RatecodeID'],\n",
    "            'fare_amount': row['fare_amount'],\n",
    "            'extra': row['extra'],\n",
    "            'mta_tax': row['mta_tax'],\n",
    "            'tip_amount': row['tip_amount'],\n",
    "            'tolls_amount': row['tolls_amount'],\n",
    "            'improvement_surcharge': row['improvement_surcharge'],\n",
    "            'total_amount': row['total_amount']\n",
    "        },\n",
    "        'geometry': {\n",
    "            'type': 'LineString',\n",
    "            'coordinates': [\n",
    "                [row['X_Longitude'], row['X_Latitude']],\n",
    "                [row['Y_Longitude'], row['Y_Latitude']]\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "geojson = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "# summary_df.to_csv(os.path.join(\"output\", data_year_month) + \".csv\")\n",
    "with open(os.path.join(\"output\", data_year_month) + \".geojson\", \"w\") as f:\n",
    "    json.dump(geojson, f, indent=4)\n"
   ],
   "id": "75a54a96bf2c12f4",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d48935a4b9da733b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
